{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9, 12, 17, 20, 31, 44, 46, 49, 54, 57]\n"
     ]
    }
   ],
   "source": [
    "filePath = 'D:\\DATA\\SVMdata\\sub4'\n",
    "#運動実行のファイルパス\n",
    "filepath1 = 'real'\n",
    "#運動想起、両運動のファイルパス\n",
    "filepath2 = 'image'\n",
    "#test用データ\n",
    "filepath3 = 'test'\n",
    "\n",
    "#指定したチャネルを読み込む用のlist\n",
    "readChanel = [9,12,17,20,31,44,46,49,54,57]\n",
    "print(readChanel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import library\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import pandas as pd\n",
    "from scipy import signal\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataクラス\n",
    "class O_Data:\n",
    "    def __init__(self, eeg, index, label):\n",
    "        self.eeg = eeg\n",
    "        self.index = index\n",
    "        self.label = label\n",
    "        self.stack = []\n",
    "\n",
    "    def push(self, item):\n",
    "        self.stack.append(item)\n",
    "\n",
    "o_data65 = list()\n",
    "R_data = list()  #  実運動のデータを格納\n",
    "RI_data = list()  # 実運動＋想起運動のデータを格納\n",
    "All_data = list()  # 全データを格納\n",
    "#検証用\n",
    "testo_data65 = list()\n",
    "testR_data = list()  #  実運動のデータを格納\n",
    "testRI_data = list()  # 実運動＋想起運動のデータを格納\n",
    "testAll_data = list()  # 全データを格納\n",
    "\n",
    "def Standardization(data): #標準化\n",
    "    after_data = scipy.stats.zscore(data)\n",
    "    b = np.average(after_data)\n",
    "    c = np.var(after_data)\n",
    "    return after_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filelist1\n",
      "['EEG_grasping_03-Mar-2020_matu_sub1-1_1day.mat', 'EEG_grasping_03-Mar-2020_matu_sub1-2_1day.mat', 'EEG_grasping_04-Mar-2020_matu_sub1-1_day2.mat', 'EEG_grasping_04-Mar-2020_matu_sub1-2_day2.mat', 'aEEG_grasping_03-Mar-2020_matu_sub1-3_1day.mat']\n",
      "Filelist2\n",
      "['EEG_grasping_03-Mar-2020_matu_sub2-1_1day.mat', 'EEG_grasping_03-Mar-2020_matu_sub2-2_1day.mat', 'EEG_grasping_03-Mar-2020_matu_sub3-1_1day.mat', 'EEG_grasping_03-Mar-2020_matu_sub3-2_1day.mat', 'EEG_grasping_04-Mar-2020_matu_sub2-1_day2.mat', 'EEG_grasping_04-Mar-2020_matu_sub2-2_day2.mat', 'EEG_grasping_04-Mar-2020_matu_sub2-3_day2.mat', 'EEG_grasping_04-Mar-2020_matu_sub3-1_day2.mat', 'EEG_grasping_04-Mar-2020_matu_sub3-2_day2.mat', 'EEG_grasping_04-Mar-2020_matu_sub3-3_day2.mat']\n",
      "Filelist3\n",
      "['EEG_grasping_03-Mar-2020_matu_sub2-3_1day.mat', 'EEG_grasping_03-Mar-2020_matu_sub3-3_1day.mat', 'aEEG_grasping_04-Mar-2020_matu_sub1-3_day2.mat']\n"
     ]
    }
   ],
   "source": [
    "file_name1 = list()  # すべての.matファイルの名前\n",
    "file_name2 = list()\n",
    "file_name3 = list()\n",
    "for file in os.listdir(filePath+\"\\\\\"+filepath1):\n",
    "    base, ext = os.path.splitext(file)\n",
    "    if ext == '.mat':\n",
    "        file_name1 = sorted(file_name1)\n",
    "        file_name1.append(file)\n",
    "print('Filelist1')\n",
    "print(file_name1)\n",
    "for file in os.listdir(filePath+'\\\\'+filepath2):\n",
    "    base, ext = os.path.splitext(file)\n",
    "    if ext == '.mat':\n",
    "        file_name2 = sorted(file_name2)\n",
    "        file_name2.append(file)\n",
    "print('Filelist2')\n",
    "print(file_name2)\n",
    "for file in os.listdir(filePath+'\\\\'+filepath3):\n",
    "    base, ext = os.path.splitext(file)\n",
    "    if ext == '.mat':\n",
    "        file_name3 = sorted(file_name3)\n",
    "        file_name3.append(file)\n",
    "print('Filelist3')\n",
    "print(file_name3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_loading\n"
     ]
    }
   ],
   "source": [
    "# 変数など\n",
    "data_directry = ''\n",
    "file_num1 = len(file_name1)\n",
    "file_num2 = len(file_name2)\n",
    "file_num3 = len(file_name3)\n",
    "\n",
    "trial_num = 30\n",
    "all_trial = (file_num1+file_num2) * trial_num\n",
    "all_d = 0\n",
    "CH = 64\n",
    "#運動実行を読み込む\n",
    "for s in range(file_num1):\n",
    "    Dictionary = scipy.io.loadmat(filePath+'\\\\'+filepath1+'\\\\'+file_name1[s])\n",
    "    for t in range(trial_num):\n",
    "        for i, key in enumerate(Dictionary.keys()):\n",
    "            if i > 2:\n",
    "                a = Dictionary[key]\n",
    "                b = a[0, t][0][0]\n",
    "                eeg = b[0][0:64, :]\n",
    "                index = b[1]\n",
    "                samplerate = b[2]\n",
    "\n",
    "                #label = b[5][0, 0]\n",
    "                label = 1\n",
    "\n",
    "                o_data = O_Data(eeg, index, label)\n",
    "                o_data65.append(o_data)\n",
    "#運動想起を読み込む\n",
    "for s in range(file_num2):\n",
    "    Dictionary = scipy.io.loadmat(filePath+'\\\\'+filepath2+'\\\\'+file_name2[s])\n",
    "    for t in range(trial_num):\n",
    "        for i, key in enumerate(Dictionary.keys()):\n",
    "            if i > 2:\n",
    "                a = Dictionary[key]\n",
    "                b = a[0, t][0][0]\n",
    "                eeg = b[0][0:64, :]\n",
    "                index = b[1]\n",
    "                samplerate = b[2]\n",
    "\n",
    "                #label = b[5][0, 0]\n",
    "                label = 0\n",
    "\n",
    "                o_data = O_Data(eeg, index, label)\n",
    "                o_data65.append(o_data)\n",
    "testall_trial = file_num3*trial_num\n",
    "#テストデータを読み込む\n",
    "for s in range(file_num3):\n",
    "    Dictionary = scipy.io.loadmat(filePath+'\\\\'+filepath3+'\\\\'+file_name3[s])\n",
    "    for t in range(trial_num):\n",
    "        for i, key in enumerate(Dictionary.keys()):\n",
    "            if i > 2:\n",
    "                a = Dictionary[key]\n",
    "                b = a[0, t][0][0]\n",
    "                eeg = b[0][0:64, :]\n",
    "                index = b[1]\n",
    "                samplerate = b[2]\n",
    "\n",
    "                label = 0\n",
    "                if s >= file_num3-2:\n",
    "                    label = 1\n",
    "\n",
    "                testo_data = O_Data(eeg, index, label)\n",
    "                testo_data65.append(testo_data)\n",
    "print(\"data_loading\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainning data\n",
      "(4500,)\n",
      "(4500, 4000)\n",
      "test data\n",
      "(900,)\n",
      "(900, 4000)\n"
     ]
    }
   ],
   "source": [
    "for n in range(all_trial):  # all_trial\n",
    "    number = list()  # restのindex\n",
    "    time = list()\n",
    "    all_d = sum(len(v) for v in o_data65[n].index) - 1\n",
    "    for i in range(all_d + 1):\n",
    "        time.append(i)\n",
    "    eeg = o_data65[n].eeg  # トライアルnのeeg\n",
    "    index = o_data65[n].index  # トライアルnのindex\n",
    "    label = o_data65[n].label  # トライアルnのlabel\n",
    "    for i in range(all_d):\n",
    "        if index[:, i] == 0:\n",
    "            number.append(i)\n",
    "    rest_time = len(number)  # rest時間のindex数\n",
    "\n",
    "    # すべてのチャンネルで行う\n",
    "    for j in range(len(readChanel)):\n",
    "        onech_eeg = eeg[readChanel[j], :]  # 一つのチャンネルのeeg\n",
    "        number = np.array(number)\n",
    "        time = np.array(time)\n",
    "        detrend = signal.detrend(onech_eeg[0:8000])  # ベースライン補正\n",
    "        Standard = Standardization(detrend)# 正規化\n",
    "        resample = signal.resample(Standard,4000)#ダウンサンプリング\n",
    "\n",
    "        All_data.append(resample)\n",
    "        \n",
    "        if label == 1:\n",
    "            #運動実行\n",
    "            R_data.append(1)\n",
    "        else:\n",
    "            #運動想起\n",
    "            R_data.append(0)\n",
    "\n",
    "R_data = np.array(R_data)\n",
    "All_data = np.array(All_data)\n",
    "\n",
    "#テストデータ\n",
    "for n in range(testall_trial):  # all_trial\n",
    "    number = list()  # restのindex\n",
    "    time = list()\n",
    "    all_d = sum(len(v) for v in testo_data65[n].index) - 1\n",
    "    for i in range(all_d + 1):\n",
    "        time.append(i)\n",
    "    eeg = testo_data65[n].eeg  # トライアルnのeeg\n",
    "    index = testo_data65[n].index  # トライアルnのindex\n",
    "    label = testo_data65[n].label  # トライアルnのlabel\n",
    "    for i in range(all_d):\n",
    "        if index[:, i] == 0:\n",
    "            number.append(i)\n",
    "    rest_time = len(number)  # rest時間のindex数\n",
    "\n",
    "    # すべてのチャンネルで行う\n",
    "    for j in range(len(readChanel)):\n",
    "        onech_eeg = eeg[readChanel[j], :]  # 一つのチャンネルのeeg\n",
    "        number = np.array(number)\n",
    "        time = np.array(time)\n",
    "        detrend = signal.detrend(onech_eeg[0:8000])  # ベースライン補正\n",
    "        Standard = Standardization(detrend)#正規化\n",
    "        resample = signal.resample(Standard,4000)#ダウンサンプリング\n",
    "\n",
    "        testAll_data.append(resample)\n",
    "        \n",
    "        if label == 1:\n",
    "            #運動実行\n",
    "            testR_data.append(1)\n",
    "        else:\n",
    "            #運動想起\n",
    "            testR_data.append(0)\n",
    "\n",
    "testR_data = np.array(testR_data)\n",
    "testAll_data = np.array(testAll_data)\n",
    "\n",
    "\n",
    "\n",
    "print(\"trainning data\")\n",
    "print(np.shape(R_data))\n",
    "print(np.shape(All_data))\n",
    "print(\"test data\")\n",
    "print(np.shape(testR_data))\n",
    "print(np.shape(testAll_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6645925925925926\n",
      "0.6728888888888889\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(All_data, R_data, test_size=0.25)\n",
    "\n",
    "\n",
    "\n",
    "model =SVC(kernel='linear')\n",
    "model.fit(X_train,Y_train)\n",
    "\n",
    "SVC(C=1.0, class_weight=None, coef0=0.0,\n",
    "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
    "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "  tol=0.001, verbose=False)\n",
    "\n",
    "print(model.score(X_train, Y_train))\n",
    "print(model.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#判別機を作る\n",
    "\n",
    "SVC(C=1.0, class_weight=None, coef0=0.0,\n",
    "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
    "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "  tol=0.001, verbose=False)\n",
    "  \n",
    "fullmodel =SVC(kernel='linear')\n",
    "fullmodel.fit(All_data,R_data)\n",
    "#modelの保存\n",
    "modelname = \"modelSVCsub4.sav\"\n",
    "pickle.dump(fullmodel,open(modelname,'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存したモデルをロードする\n",
    "#時系列データで検証\n",
    "loaded_model = pickle.load(open(modelname, 'rb'))\n",
    "result = loaded_model.score(testAll_data, testR_data)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"C\":np.arange(0.1,1,0.05),\n",
    "    \"kernel\":[\"linear\", \"poly\", \"rbf\", \"sigmoid\"],\n",
    "    \"gamma\":np.arange(0.0001,0.1,0.05)\n",
    "}\n",
    "grid = GridSearchCV(fullmodel, params,scoring=\"accuracy\", cv=5)\n",
    "grid.fit(All_data,R_data)\n",
    "\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)\n",
    "\n",
    "pred = grid.predict(testAll_data)\n",
    "print(classification_report(testR_data, pred))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c7128e48e345da2e2e89e1cddc0757c02258d47da469c5be88316b2da9c93278"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
